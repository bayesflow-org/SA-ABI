{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss, mean_absolute_error\n",
    "\n",
    "# Set paths\n",
    "#os.chdir(os.path.dirname(__file__))\n",
    "sys.path.extend([\n",
    "    os.path.abspath(os.path.join(\"../..\")),\n",
    "    os.path.abspath(os.path.join(\"../../../BayesFlow_dev/BayesFlow/\"))\n",
    "])\n",
    "\n",
    "# Import from relative paths\n",
    "from src.python.helpers import MaskingConfigurator, get_latex_results_table\n",
    "from src.python.training import load_training_data\n",
    "from src.python.ensemble import get_ensemble_predictions\n",
    "import bayesflow as bf\n",
    "\n",
    "# Silence tensorflow warnings and BayesFlow info logging\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "POWER_SCALINGS = [True, False]\n",
    "N_ENSEMBLE_MEMBERS = 20\n",
    "N_CHUNKS = 200\n",
    "N_MODELS = 4\n",
    "SUMMARY_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "try: \n",
    "    with open(f\"../../data/levy_comparison/predictions/preds_sim_powerscaled.pkl\", \"rb\") as file:\n",
    "        scaled_sim_dict = pickle.load(file)\n",
    "\n",
    "    with open(f\"../../data/levy_comparison/predictions/preds_sim_unscaled.pkl\", \"rb\") as file:\n",
    "        unscaled_sim_dict = pickle.load(file)\n",
    "    \n",
    "except:\n",
    "    os.makedirs(\"../../data/levy_comparison/predictions\", exist_ok=True)\n",
    "    \n",
    "    # Takes ~30 seconds for initial data configuration and ~20 seconds per network on 8000 test data sets\n",
    "    for power_scaling in POWER_SCALINGS:\n",
    "        scaling_name = \"sim_powerscaled\" if power_scaling else \"sim_unscaled\"\n",
    "\n",
    "        # Load and configure data\n",
    "        test_data = load_training_data(scaling_name, \"test\")\n",
    "        masking_configurator = MaskingConfigurator(power_scaling=power_scaling)\n",
    "        test_data = masking_configurator(test_data)\n",
    "\n",
    "        embeddings, pmps, logits = get_ensemble_predictions(\n",
    "            path=f\"ensemble_checkpoints/{scaling_name}\", \n",
    "            data=test_data, \n",
    "            num_models=N_MODELS,\n",
    "            summary_dim=SUMMARY_DIM, \n",
    "            predict_in_chunks=True,\n",
    "            num_chunks=N_CHUNKS\n",
    "        )\n",
    "    \n",
    "        pred_dict = {\n",
    "            \"preds\": pmps,\n",
    "            \"logits\": logits,\n",
    "            \"summary_output\": embeddings,\n",
    "            \"sim_indices\": test_data[\"model_indices\"]\n",
    "        }\n",
    "\n",
    "        with open(f'../../data/levy_comparison/predictions/preds_{scaling_name}.pkl', 'wb') as file:\n",
    "            pickle.dump(pred_dict, file)\n",
    "\n",
    "    with open(f\"../../data/levy_comparison/predictions/preds_sim_powerscaled.pkl\", \"rb\") as file:\n",
    "        scaled_sim_dict = pickle.load(file)\n",
    "\n",
    "    with open(f\"../../data/levy_comparison/predictions/preds_sim_unscaled.pkl\", \"rb\") as file:\n",
    "        unscaled_sim_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Measure inference times\n",
    "# inference_times_per_net = {}\n",
    "\n",
    "# for power_scaling in POWER_SCALINGS:\n",
    "#     scaling_name = \"sim_powerscaled\" if power_scaling else \"sim_unscaled\"\n",
    "\n",
    "#     # Load and configure data\n",
    "#     test_data = load_training_data(scaling_name, \"test\")\n",
    "#     masking_configurator = MaskingConfigurator(power_scaling=power_scaling)\n",
    "#     test_data = masking_configurator(test_data)\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     embeddings, pmps, logits = get_ensemble_predictions(\n",
    "#         path=f\"ensemble_checkpoints/{scaling_name}\", \n",
    "#         data=test_data, \n",
    "#         num_models=N_MODELS,\n",
    "#         summary_dim=SUMMARY_DIM, \n",
    "#         predict_in_chunks=True,\n",
    "#         num_chunks=N_CHUNKS\n",
    "#     )\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     pred_dict = {\n",
    "#         \"preds\": pmps,\n",
    "#         \"logits\": logits,\n",
    "#         \"summary_output\": embeddings,\n",
    "#         \"sim_indices\": test_data[\"model_indices\"]\n",
    "#     }\n",
    "#     inference_times_per_net[str(power_scaling)] = (end_time - start_time) / N_ENSEMBLE_MEMBERS\n",
    "\n",
    "# # Print times\n",
    "# print(\"Seconds powerscaled inference per net:\", inference_times_per_net[\"True\"])\n",
    "# print(\"Mins powerscaled inference per net:\", inference_times_per_net[\"True\"] / 60)\n",
    "# print(\"Mins powerscaled 1000 priors training+inference:\", 66 + (inference_times_per_net[\"True\"] / 60) * 1000)\n",
    "# print(\"Mins unscaled 1000 priors training+inference:\", (66 + inference_times_per_net[\"False\"] / 60) * 1000)\n",
    "# print(\"Hours powerscaled 1000 priors training+inference:\", (66 + (inference_times_per_net[\"True\"] / 60) * 1000) / 60)\n",
    "# print(\"Hours unscaled 1000 priors training+inference:\", ((66 + inference_times_per_net[\"False\"] / 60) * 1000) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dicts = [scaled_sim_dict, unscaled_sim_dict]\n",
    "metrics_dict = {}\n",
    "metrics_names = [\"ECE\", \"Brier Score\", \"MAE\", \"Accuracy\"]\n",
    "scaling_names = [\"sim_powerscaled\", \"sim_unscaled\"]\n",
    "\n",
    "# Get Expected Calibration Error, Maximum Calibration Error, MAE, Accuracy\n",
    "for i, sim_dict in enumerate(sim_dicts):\n",
    "    metrics = np.zeros((N_ENSEMBLE_MEMBERS, N_MODELS, len(metrics_names)))\n",
    "    m_true = sim_dict[\"sim_indices\"]\n",
    "\n",
    "    for network in range(N_ENSEMBLE_MEMBERS):\n",
    "        m_pred = sim_dict[\"preds\"][network, ...]\n",
    "\n",
    "        eces, probs_true, probs_pred = bf.computational_utilities.expected_calibration_error(m_true=m_true, m_pred=m_pred)\n",
    "        brier_scores = [brier_score_loss(y_true=m_true[:, m], y_prob=m_pred[:, m]) for m in range(N_MODELS)]\n",
    "        maes = mean_absolute_error(y_true=m_true, y_pred=m_pred, multioutput=\"raw_values\")\n",
    "        accuracies = [np.mean(m_true[:, m] == (m_pred[:, m] > .5)) for m in range(N_MODELS)]\n",
    "        \n",
    "        metrics[network, :, 0] = eces\n",
    "        metrics[network, :, 1] = brier_scores\n",
    "        metrics[network, :, 2] = maes\n",
    "        metrics[network, :, 3] = accuracies\n",
    "\n",
    "    metrics_dict[scaling_names[i]] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECE</th>\n",
       "      <th>Brier Score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Network 1</th>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.985281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 2</th>\n",
       "      <td>0.012118</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.047555</td>\n",
       "      <td>0.962094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 3</th>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.989062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 4</th>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.993281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 5</th>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.987313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 6</th>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>0.987688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 7</th>\n",
       "      <td>0.008318</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.987719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 8</th>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.012078</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.985250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 9</th>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.989625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 10</th>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.021141</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.971719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 11</th>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.989344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 12</th>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.990313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 13</th>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.988812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 14</th>\n",
       "      <td>0.010844</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.026668</td>\n",
       "      <td>0.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 15</th>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.989875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 16</th>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.994563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 17</th>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.979406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 18</th>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.018930</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.975531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 19</th>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.987906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 20</th>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.988938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ECE  Brier Score       MAE  Accuracy\n",
       "Network 1   0.008775     0.011805  0.016615  0.985281\n",
       "Network 2   0.012118     0.028105  0.047555  0.962094\n",
       "Network 3   0.007228     0.009029  0.012031  0.989062\n",
       "Network 4   0.005228     0.005826  0.007289  0.993281\n",
       "Network 5   0.008009     0.010365  0.014341  0.987313\n",
       "Network 6   0.008039     0.010362  0.013981  0.987688\n",
       "Network 7   0.008318     0.010263  0.013934  0.987719\n",
       "Network 8   0.009441     0.012078  0.016548  0.985250\n",
       "Network 9   0.007846     0.009115  0.011449  0.989625\n",
       "Network 10  0.011540     0.021141  0.034136  0.971719\n",
       "Network 11  0.006796     0.009187  0.012514  0.989344\n",
       "Network 12  0.007288     0.008252  0.010223  0.990313\n",
       "Network 13  0.007758     0.009581  0.012675  0.988812\n",
       "Network 14  0.010844     0.017299  0.026668  0.978000\n",
       "Network 15  0.007612     0.008794  0.011034  0.989875\n",
       "Network 16  0.004294     0.004975  0.006179  0.994563\n",
       "Network 17  0.010136     0.016331  0.024498  0.979406\n",
       "Network 18  0.010199     0.018930  0.030185  0.975531\n",
       "Network 19  0.007658     0.009980  0.013689  0.987906\n",
       "Network 20  0.007246     0.009358  0.012892  0.988938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tables\n",
    "scaled_validation = pd.DataFrame(\n",
    "    np.mean(metrics_dict[\"sim_powerscaled\"], axis=1), columns=metrics_names\n",
    ")\n",
    "scaled_validation.index = [f'Network {i}' for i in range(1, N_ENSEMBLE_MEMBERS + 1)]\n",
    "scaled_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECE</th>\n",
       "      <th>Brier Score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Network 1</th>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.996437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 2</th>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.994188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 3</th>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.018302</td>\n",
       "      <td>0.984313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 4</th>\n",
       "      <td>0.007530</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>0.030037</td>\n",
       "      <td>0.976719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 5</th>\n",
       "      <td>0.005656</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>0.025402</td>\n",
       "      <td>0.980812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 6</th>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.997938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 7</th>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.996625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 8</th>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.982125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 9</th>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.997313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 10</th>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 11</th>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 12</th>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.970156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 13</th>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>0.990281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 14</th>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.995875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 15</th>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.989844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 16</th>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.996875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 17</th>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.996750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 18</th>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.996625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 19</th>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.992406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network 20</th>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.035949</td>\n",
       "      <td>0.971812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ECE  Brier Score       MAE  Accuracy\n",
       "Network 1   0.003139     0.003237  0.003798  0.996437\n",
       "Network 2   0.004203     0.005006  0.006647  0.994188\n",
       "Network 3   0.008699     0.012392  0.018302  0.984313\n",
       "Network 4   0.007530     0.017558  0.030037  0.976719\n",
       "Network 5   0.005656     0.014477  0.025402  0.980812\n",
       "Network 6   0.001933     0.001928  0.002288  0.997938\n",
       "Network 7   0.002714     0.002878  0.003570  0.996625\n",
       "Network 8   0.008960     0.013640  0.020500  0.982125\n",
       "Network 9   0.002456     0.002379  0.002887  0.997313\n",
       "Network 10  0.002239     0.002549  0.003206  0.997000\n",
       "Network 11  0.003203     0.003455  0.004151  0.996000\n",
       "Network 12  0.007729     0.021626  0.038449  0.970156\n",
       "Network 13  0.005855     0.007701  0.010785  0.990281\n",
       "Network 14  0.003566     0.003754  0.004567  0.995875\n",
       "Network 15  0.006265     0.008007  0.011204  0.989844\n",
       "Network 16  0.002734     0.002816  0.003408  0.996875\n",
       "Network 17  0.002822     0.002932  0.003443  0.996750\n",
       "Network 18  0.002850     0.002893  0.003464  0.996625\n",
       "Network 19  0.005066     0.006363  0.008575  0.992406\n",
       "Network 20  0.007945     0.020361  0.035949  0.971812"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_validation = pd.DataFrame(\n",
    "    np.mean(metrics_dict[\"sim_unscaled\"], axis=1), columns=metrics_names\n",
    ")\n",
    "unscaled_validation.index = [f'Network {i}' for i in range(1, N_ENSEMBLE_MEMBERS + 1)]\n",
    "unscaled_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation results to combine with application results\n",
    "with open(f\"../../data/levy_comparison/validation_results/validation_scaled_unscaled.pkl\", \"wb\") as file:\n",
    "    val_results_dict = {\n",
    "        \"scaled\": scaled_validation,\n",
    "        \"unscaled\": unscaled_validation\n",
    "    }\n",
    "    pickle.dump(val_results_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
